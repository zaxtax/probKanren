%% The first command in your LaTeX source must be the \documentclass command.
%%
%% Options:
%% twocolumn : Two column layout.
%% hf: enable header and footer.
\documentclass[
% twocolumn,
% hf,
]{ceurart}

%%
%% One can fix some overfulls
% \sloppy

%%
%% Minted listings support 
%% Need pygment <http://pygments.org/> <http://pypi.python.org/pypi/Pygments>
\usepackage{minted}
\usepackage{syntax}
\shortverb{\|}
%% auto break lines
\setminted{breaklines=true}

\usepackage{cleveref}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% Rights management information.
%% CC-BY is default license.
\copyrightyear{2021}
\copyrightclause{Copyright for this paper by its authors.
  Use permitted under Creative Commons License Attribution 4.0
  International (CC BY 4.0).}

%%
%% This command is for the conference information
\conference{PLP 2021}

%%
%% The "title" command
\title{probKanren: A Simple Probabilistic extension for microKanren}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
\author[1]{Robert Zinkov}[%
%orcid=0000-0002-0877-7063,
email=zinkov@robots.ox.ac.uk,
url=https://zinkov.com/,
]
\address[1]{Dept. of Engineering Science, University of Oxford,
  25 Banbury Rd, Oxford, UK}

\author[2]{William E. Byrd}[%
%orcid=0000-0001-7116-9338,
email=webyrd@uab.edu,
url=http://webyrd.net/,
]
\address[2]{Hugh Kaul Precision Medicine Institute, University of Alabama at Birmingham, 705 20th Street S., Birmingham, AL 35233, United States of America}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Probabilistic programming can be conceptually seen as generalisation
  of logic programming where instead of just returning a set of
  answers to a given query, we also return a probability distribution
  over those answers. But many contemporary probabilistic logic
  programming languages implementations are not simple extensions of
  existing logic programming languages but instead involve their own
  unique implementations. Here we introduce \textsc{probKanren}, a simple
  extension to microKanren that transforms it into a probabilistic
  programming language without needing to make any modifications to
  the underlying logic language's search. We use several illustrative
  examples from the probabilistic programming and program synthesis
  literature to demonstrate the practicality of the approach.

  
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\begin{keywords}
  Probabilistic Logic Programming \sep
  miniKanren \sep
  Probabilistic Programming \sep
  Sequential Monte Carlo
  %Particle Filtering
  %relational programming
  %logic programming
\end{keywords}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

Conceptually, logic programming provides a way to model
non-determinism. This is accomplished by maintaining a set of answers
that satisfy a set of logical constraints. A natural generalisation
to this domain is adding a notion of uncertainty to this set of answers
by associating with them a probability distribution.

But the conceptual simplicity of this sort of generalisation is not
reflected in the complexity of many existing probabilistic logic
programming systems.  They often involve implementing sophisticated
inference algorithms and the underlying systems are not just
implemented on top of existing logic programming systems.

We believe that a conceptually simple extension deserves a
conceptually simple implementation to go along with it. We thus
contribute a simple way to extend \textsc{microKanren}, a small logic
programming domain-specific language such that it becomes a
probabilistic programming language.

\subsection{Illustrated Example}

To help explain how to use \textsc{probKanren} we introduce the following example:

%TODO: Examples should use the grammar defined in the paper

\begin{minted}{Scheme}
  (run 1000 (q)
   (conj
    (normal 0 3 q)
    (normal q 2 4)))
\end{minted}

%% \begin{minted}{Scheme}
%%   (run 1000 (q)
%%     (uniform 0 1 q)
%%     (bern q 1.0))
%% \end{minted}

In the above program, we have a probabilistic model for the Gaussian
unknown mean problem. We observe a value 4 from the $\mathcal{N}(q,2)$
distribution, and that $q$ has a prior distribution of $\mathcal{N}(0, 3)$.
This \textsc{probKanren} program draws 1000 samples from a conditional normal distribution
that represents the posterior probability distribution associated with $q$.

\section{Related Work}

There is a rich history of extending logic programming formalisms to
support probabilistic inference. Early systems like
PRISM\cite{sato1997prism} and ProbLog\cite{de2007problog} allowed
associating discrete distributions with facts. Early versions of
ProbLog were also built on top of Prolog, matching one of the goals of
our work. Later work\cite{gutmann2010extending} introduces
distribution clauses so that some continuous distributions like
Gaussians can be represented. Other work extended these methods
further while focusing on efficient exact inference algorithms like
weighted model integration\cite{islam2012inference,
  belle2015probabilistic}. Our work is most similar to
\cite{gutmann2011magic}, except that while they combine their forward
reasoning with an importance sampler we use a particle cascade instead
which can be more sample efficient.

\section{Background}

\subsection{microKanren}

\textsc{microKanren}\cite{10.1145/2989225.2989230, daniel2018reasoned}
is a pure logic programming language embedded in Scheme. The language
consists of a set of terms, a set of goal primitives, and two run
forms that turn goal queries into a set of answers. The goal primitives
consist of a \texttt{fresh} form for introducing logic variables, a
unification primitive \texttt{==}, a conjunction combinator
\texttt{conj}, a disjunction combinator \texttt{disj}, and ways to
define and apply relations. Further forms are shown in detail in
\Cref{fig:grammar}.

Goal expressions represent a possibly backtracking search
procedure. These goals all take as input some state and output a
stream of possible output states. We run these goals by starting with
an initial state that holds an empty substitution dictionary, and
passing it into the top-level goal expression which then passes it
recursively down to sub-expressions. Encountering \texttt{fresh}
extends the lexical environment with a binding between a lexical
variable and a logic variable; \texttt{conj} will apply the first goal
to the state passed in, and then apply the second goal to the states
associated with each resulting stream from the first goal and finally
unify the results; \texttt{disj} will apply both goals to the same
input state and concatenate the resulting streams; and \texttt{==}
unifies its arguments in the context of the current state, discarding
any streams which fail to unify.

To handle goal expressions that might diverge, the streams are
expanded in an interleaving\cite{kiselyov2005backtracking} fashion,
giving each branch a chance to produce answers. This interleaving search
is sound and complete\cite{rozplokhas2019certified}.

\subsection{Grammar and Definitions}

\begin{figure}
  \centering
  \begin{grammar}
<prog> ::= (run <number> (<id>) <goal-expr>)

<goal-expr> ::= (disj <goal-expr> <goal-expr>) \alt
	        (conj <goal-expr> <goal-expr>) \alt
                (fresh (<id>) <goal-expr>) \alt
		(== <term-expr> <term-expr>) \alt
		(letrec-rel ((<id> (<id> ...) <goal-expr>) ...) \\
		\hspace{\grammarindent} <goal-expr>) \alt
		(call-rel <lexical-var-ref> <term-expr> ...) \alt
		(prim-rel-call <lexical-var-ref> <term-expr> ...) \alt
		(delay <goal-expr>)

<term-expr> ::= (quote <datum>) \alt
                <lexical-var-ref> \alt
                (cons <term-expr> <term-expr>) \alt
                <term>

<term> ::= <number> \alt
           \#f | \#t \alt
	   <symbol> \alt
	   (<term> . <term>) \alt
	   <logic-var>

  \end{grammar}
  \caption{Grammar for \textsc{microKanren}}
  \label{fig:grammar}
\end{figure}

To create \textsc{probKanren}, we extend this grammar with distribution
clauses such as \texttt{normal} and \texttt{bern}. Distribution clauses
take as arguments the parameters of the distribution and a last argument
representing a draw from that distribution. For example, \texttt{(normal 0 1 x)}
means \texttt{x} represents a draw from the $\mathcal{N}(0,1)$ distribution.

These are just another type of goal expression. We do not need to add
a notion of probabilistic variables to the language grammar, as they
can treated as logic variables constrained in a particular way. The
semantics of the language though does change from an answer set to a
probability distribution on that answer set.

We follow the semantics of \cite{staton2016semantics}, this is a
denotational semantics where each language form is associated with a
measurable function, and an operational semantics of a sampler.

\subsection{Probabilistic Programming}

Probabilistic Programming Languages\cite{wood2014new,
  van2018introduction} are a family of domain-specific languages for
posing and efficiently solving probabilistic modelling problems. At
their core, all have a way to \texttt{sample} and \texttt{observe}
data under a probability distribution or Markov kernel.

There are many inference algorithms for probabilistic programming
languages, but methods based on likelihood-weighting and Sequential
Monte Carlo algorithms are the simplest to implement.

\subsection{Sequential Monte Carlo}

Sequential Monte Carlo\cite{chopin2020introduction}(SMC) is an efficient
online way to sample from probabilistic models, which is especially suited for
state-space domains. If we imagine our probabilistic programs as
straight-line programs with no control-flow we can imagine numbering
every sample function $f_1, f_2, \ldots, f_n$ and every observe
function $g_1, g_2, \ldots, g_n$ then our probability density over our
latent variables $x_{0:T}$ and observed data $y_{0:T}$ can be defined as:

\begin{equation}
  p(x_{0:T}, y_{0:T}) = p(x_0)\prod_{t=1}^T f_t(x_t \mid x_{t-1})\prod_{t=0}^T g_t(y_t \mid x_t)
\end{equation}

\subsection{Sequential Importance Sampling}

The simplest way to sample from our target distribution $p(x_{0:T}
\mid y_{0:T})$ is to sample from a sequence of intermediary
distributions $p(x_{0:t} \mid y_{0:t})$ where $t$ goes from $1$ to
$T$. We do this by sampling a population of $N$ particles
$\{x^{(1)}_t, \ldots, x^{(i)}_t, \ldots x^{(N)}_t\}$ from a proposal
distribution $q(x_t \mid x_{0:t-1}, y_{0:t})$, which when combined
with a set of importance weights $\{w^{(1)}_t, \ldots, w^{(i)}_t,
\ldots w^{(N)}_t\}$ lets us approximate each intermediary
distribution.

Thanks to the recurrence relation:

\begin{equation}
p(x_{0:t} \mid y_{0:t}) = p(x_{0:t-1} \mid y_{0:t-1}) \frac{f_t(x_t \mid x_{t-1}) g_t(y_t \mid x_t)}{p(y_t \mid y_{0:t-1})}
\end{equation}

we know in $T$ rounds we compute the desired distribution as follows:

Initialise with:

\begin{align}
x_0^{(i)} &\sim p(x_0) \\
w_0^{(i)} &= 1/N
\end{align}

Then for $t$ from $1$ to $T$

\begin{align}
  x_t^{(i)} &\sim q(x_t \mid x^{(i)}_{0:t-1}) \\
  w_t^{(i)} &\propto w_{t-1}^{(i)} \frac{f(x^{(i)}_t \mid x^{(i)}_{t-1})g(y_t \mid x^{(i)}_t)}{q(x^{(i)}_t \mid x^{(i)}_{0:t-1})}
\end{align}

We get the best results if $q(x_t \mid x_{0:t-1})$ is equal to $p(x_t \mid x_{0:t-1}, y_{0:t})$.

\subsection{Sequential Importance Resampling}

Unfortunately, over time SIS is likely to lead to most of the
importance weight in a small fraction of the particles, with the rest
of the particles having negligible weight. This is usually called
\emph{weight degeneracy}. We address this sample efficiency issue in
the standard way by replicating the particles with high weight and
dropping the ones with low weight. This is called a resampling step,
and it happens after each round. Resampling effectively removes
particles with low weight and duplicates particles with higher weight
by sampling with replacement our existing particles.

\begin{align*}
  a_t^{(i)} &\sim r(w_{t-1}^{(1:N)}) \\
  x_t^{(i)} &\sim q(x_t \mid x^{(a_t^{(i)})}_{0:t-1}) \\
  w_t^{(i)} &\propto w_{t-1}^{(i)} \frac{f(x^{(i)}_t \mid x^{(i)}_{t-1})g(y_t \mid x^{(i)}_t)}{q(x^{(i)}_t \mid x^{(i)}_{0:t-1})}
\end{align*}

For each particle $i$, resampling tells us which of the existing
particles $a_i$ will be its ancestor. We set $r(w) =
\text{Categorical}(w)$, which is called multinomial resampling but
there are other methods as well\cite{douc2005comparison}.

\subsection{Particle Cascade}

Unfortunately, SMC as defined here requires having access to all the
particles at every step in the process. This conflicts with the
functional nature of our implementation. Instead we make use of
Particle Cascades \cite{PaigeWDT14}, removing this barrier allowing every
particle to be resampled asynchronously with the associated weights
being relative to a global running average. % double-check this

\section{Proposed Method}

We propose to extend \textsc{microKanren} by turning the search into an
SMC sampler. We accomplish this by augmenting each of the search
streams with a set of particles. These particles represent the
empirical distribution of that stream. Each particle has associated
with it a substitution of all the logic and random variables as well
as a weight that is proportional to the likelihood of the
substitution.

We follow \cite{gutmann2010extending} and place the following restrictions
on our distribution clauses and the random variables they specify.

Firstly, the arguments of distribution clauses must be
grounded. Secondly, a random variable cannot unify with any arithmetic
expression.

An initial set of particles is created from the probabilistic program
when it is first run. When encountering primitives such as
\texttt{normal} we first check if all the parameter terms are grounded
and then if the last argument is fresh, we sample a value for it for
each particle and then add this sampled value along with the
associated logic variable to the substitution associated with that
particle. If all the terms are ground, we treat the primitive like an
observation statement and multiply the weights of each substitution
with the likelihood of the observation.

As conjunctions (\texttt{conj}) are encountered, all particles in all
output streams from the first goal become part of the initial states
that are each passed to the second goal.

As disjunctions (\texttt{disj}) are encountered, we split evenly the
number of particles allocated to each stream. Whenever we encounter a
unification primitive, we run a resampling step. This helps to prune
particles with low weight and replicate particles with high weight.

As an optimisation, we may create more particles during resampling
based on a globally stored counter of the effective sample size of
all particles across all streams.

This extension does not modify the search and streams are managed
exactly as in \textsc{microKanren}. An additional advantage, due to
the \text{microKanren} search being complete, we are guaranteed to
recover the true posterior as all paths of the search space will
eventually be explored given enough particles.

\section{Experiments}

We validate that \textsc{probKanren} is at least as expressive as other probabilistic
logic programming languages by implementing the Friends who Smoke model.

Friends who Smoke is a probabilistic logic program which models the
social nature of who smokes cigarettes. The model predicts that people
who are friends with people who smoke are more likely to smoke. We
replicate the example on
\url{https://dtai.cs.kuleuven.be/problog/tutorial/basic/05_smokers.html}
using 2000 particles and get an empirical distribution that seems to
match up with the discrete distribution returned from ProbLog.

%% Compare to birch or Anglican on some top examples as well

%% We could include experiment from Noah Goodman's dippl work like a semantic parsing
%% example\\ \url{http://dippl.org/examples/semanticparsing.html}

%% We could include program synthesis experiment, where probabilities
%% allow us to specify a soft preference for using certain language
%% primitives in a similar spirit to
%% \textsc{rKanren}\cite{swords2013rkanren} or neural-guided search
%% \cite{zhang2018neural}.

\section{Conclusions}

We made a simple-to-implement extension to \textsc{microKanren} that
lets us support probabilistic inference on both discrete and
continuous distributions. The approach does not require modifying the
underlying search algorithm or touching any of the backtracking code and
comes with a theoretical guarantee that if the underlying search is
complete then the probabilistic extension will recover the true
posterior given enough particles.

%% \begin{table*}
%%   \caption{Frequency of Special Characters}
%%   \label{tab:freq}
%%   \begin{tabular}{ccl}
%%     \toprule
%%     Non-English or Math&Frequency&Comments\\
%%     \midrule
%%     \O & 1 in 1,000& For Swedish names\\
%%     $\pi$ & 1 in 5& Common in math\\
%%     \$ & 4 in 5 & Used in business\\
%%     $\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
%%   \bottomrule
%% \end{tabular}
%% \end{table*}

%% To set a wider table, which takes up the whole width of the page's
%% live area, use the environment \verb|table*| to enclose the table's
%% contents and the table caption.  As with a single-column table, this
%% wide table will ``float'' to a location deemed more
%% desirable. Immediately following this sentence is the point at which
%% Table~\ref{tab:commands} is included in the input file; again, it is
%% instructive to compare the placement of the table here with the table
%% in the printed output of this document.

%% \begin{table}
%%   \caption{Some Typical Commands}
%%   \label{tab:commands}
%%   \begin{tabular}{ccl}
%%     \toprule
%%     Command &A Number & Comments\\
%%     \midrule
%%     \texttt{{\char'134}author} & 100& Author \\
%%     \texttt{{\char'134}table}& 300 & For tables\\
%%     \texttt{{\char'134}table*}& 400& For wider tables\\
%%     \bottomrule
%%   \end{tabular}
%% \end{table}


%% The ``\verb|figure|'' environment should be used for figures. One or
%% more images can be placed within a figure. If your figure contains
%% third-party material, you must clearly identify it as such, as shown
%% in the example below.
%% \begin{figure}
%%   \centering
%%   %\includegraphics[width=\linewidth]{sample-franklin}
%%   \caption{1907 Franklin Model D roadster. Photograph by Harris \&
%%     Ewing, Inc. [Public domain], via Wikimedia
%%     Commons. (\url{https://goo.gl/VLCRBB}).}
%% \end{figure}

%% Define the bibliography file to be used
\bibliography{main}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\end{document}
